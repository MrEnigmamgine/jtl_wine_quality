{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ad4e84",
   "metadata": {},
   "source": [
    "\n",
    "# Predicting the Quality Score of Wine Using Machine Learning\n",
    "![wines-lined-up](./img/wine-tasting.jpg)\n",
    "#### Sep 22, 2022\n",
    "- [Luis Arce]( https://github.com/LuisVArce)\n",
    "- [Tim Keriazes]( https://github.com/tim-keriazes)\n",
    "- [Joshua Mayes]( https://github.com/MrEnigmamgine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization modules\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Helpers\n",
    "import helpers\n",
    "import wrangle\n",
    "import model\n",
    "import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish some color themes for the notebook to mimic the colors of wine.\n",
    "wine_colors = ['#efdaa3', '#8c0f0a']\n",
    "alt_white = '#eccd13'\n",
    "wine_palette = sns.color_palette(wine_colors)\n",
    "wine_palette_r = sns.color_palette(list(reversed(wine_colors)))\n",
    "sns.set_palette(wine_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this notebook:\n",
    "This notebook presents a breif overview the key techniques, findings, and acheivements from the project and summarizes the results of our efforts.\n",
    "\n",
    "### Project Description:\n",
    "Our project examines 11 quantitative features of red/white wine data sets from the Vihno Verde region of Portugal. Using the physicochemical features/breakdown of the wine, we built a predictive machine learning model with a target variable of quality score. Our insights, discoveries, and modeling offer a distinct advantage to wine producers/stakeholders/distributors by using a wine's chemical composition and predicting its associated quality score.\n",
    "\n",
    "\n",
    "### Notebook Outline:\n",
    "<!-- 1. Intro\n",
    "2. Executive Summary\n",
    "3. Data Wrangling\n",
    "4. Split\n",
    "5. Exploration Highlights\n",
    "    6. Stats Tests?\n",
    "    8. Clusters\n",
    "        7. Scale\n",
    "9. Modeling\n",
    "10. Conclusion\n",
    "11. Next Steps -->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## About the data\n",
    "Our project makes use of the [Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php), which is a labeled dataset consisting of 6500 observations.  Each observation represents a red or white Vihno Verde whine from the Portugal region and includes the physicochemical composition of the wine as well as a labeled `quality` score indicating wine expert's opinion of the wine on a scale of 1 to 10.\n",
    "\n",
    "\n",
    "### Target variable\n",
    "**`quality`** - Quality score is the median score given to associated wine based off the rankings of three industry experts\n",
    "\n",
    "<div style=\"background-color: #f26200; color: white; border-radius: 25px; padding: 15px; width: 55%\">\n",
    " <strong>Caution!</strong> <br>\n",
    "  Models trained on biased data will reflect the bias of the humans that labeled it.  <br>\n",
    "  Because this data was created by a small group, there is a high risk of bias.\n",
    "</div>\n",
    "\n",
    "### Data Dictionary\n",
    "| **Variable Name** | **Explanation** | **Unit** | **Values** |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| Fixed Acidity |  Acids that do not evaporate readily (Tartaric Acid) | g/L | Float |\n",
    "| Volatile Acidity | Acids evaporate readily (Acetic acid) | g/L | Float |\n",
    "| Citric Acid | level of Citric acid | g/L | Float |\n",
    "| Residual Sugar | Sugar that remains after fermenation | g/L | Float |\n",
    "| Chlorides | Sodium Chloride content | g/L | Float |\n",
    "| Free Sulfur Dioxide | Levels of free, gaseous sulfur dioxide | mg/L | Float |\n",
    "| Total Sulfur Dioxide | Total Level of Sulfur Dioxide | mg/L | Float |\n",
    "| Density | Density in relation to water | g/cm^3 | Float |\n",
    "| pH| Acidity of the wine | 1-14 | Float |\n",
    "| Sulphates | Level of potassium sulfate | g/L | Float |\n",
    "| Alcohol | Alcohol by Volume per wine | ABV% | Float |\n",
    "| Quality |  The median value of at least 3 independent evualations by wine experts| 1-10 | Integer |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Challenges and preparation\n",
    "The dataset used was a very clean dataset.  There were zero null values and none of the values could be identified as obviously erroneous.  However, we discovered 1,177 duplicate records which we dropped leaving us with 5320 observations remaining after cleaning, 1359 of which are red wines and 3961 of which are white wines. \n",
    "\n",
    "## Outliers\n",
    "Identifying outliers was a particularly challenging process due to the differences between red and white wines.  Effectively we needed to consider outliers twice, once for each type of wine.  Rather than relying on a cookie-cutter method such as the IQR method, we took a subjective approach and thought critically about which values would be considered normal for a wine of this type.  Handling outliers was particularly helpful during the exploration process because it allowed us to create better charts while taking into account the type of wine the data was coming from.\n",
    "\n",
    "## Legal Definitions\n",
    "Researching the legal definitions of wines was also a particularly helpful endeavor.  By identifying the differences between EU and US laws we became more familiar with what is acceptable in a wine.  We found that the most important qualities in the US and EU laws were Sulfur Dioxide and Volatile Acidity.  EU's laws were more restrictive, but had varying limits based on how much residual sugar was in a wine.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <strong>Red</strong>\n",
    "        </td>\n",
    "        <td>\n",
    "            <strong>White</strong>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            SO2 : 350 mg/L\n",
    "        </td>\n",
    "        <td>\n",
    "            SO2 : 350 mg/L\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            VA : 1.4 g/L\n",
    "        </td>\n",
    "        <td>\n",
    "            VA : 1.5 g/L\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "#### EU\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <strong>Red</strong>\n",
    "        </td>\n",
    "        <td>\n",
    "            <strong>White</strong>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr >\n",
    "        <td>\n",
    "            SO2 limits by sugar\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <td>\n",
    "                        sugar &lt; 5g/L\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        150 mg/L\n",
    "                    </td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td>\n",
    "                        5g/L &lt; sugar &lt; 35 g/L\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        250 mg/L\n",
    "                    </td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td>\n",
    "            SO2 limits by sugar:\n",
    "            <table >\n",
    "                <tr>\n",
    "                    <td>\n",
    "                        sugar &lt; 5g/L\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        200 mg/L\n",
    "                    </td>\n",
    "                </tr>\n",
    "                <tr >\n",
    "                    <td>\n",
    "                        5g/L &lt; sugar &lt; 35 g/L\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        250 mg/L\n",
    "                    </td>\n",
    "                </tr>\n",
    "                <tr >\n",
    "                    <td>\n",
    "                        35 g/L &lt; sugar\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        400 mg/L\n",
    "                    </td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr >\n",
    "        <td>\n",
    "            VA : 1.2 g/L\n",
    "        </td>\n",
    "        <td >\n",
    "            VA : 1.08 g/L\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "[source 1](https://www.wineshopathome.com/understanding-sulfur-levels-wine/)  \n",
    "[source 2](https://www.law.cornell.edu/cfr/text/27/4.21)  \n",
    "[source 3](https://www.mpi.govt.nz/dmsdocument/34896-European-Union-Wine-OMAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Feature Engineering\n",
    "\n",
    "#### Hydronium\n",
    "Potential Hydrogen (pH) is an arbitrary scale from 0 to 14 that describes how acidic or basic a solution is.  This is determined by its Hydronium concentration.  We exctacted the hydronium concentration knowing that the formula for pH is $-\\log{H_3O{+}}$, in turn the formula used to derive the hydronium concentration is $10^{-pH}$.  We chose to use hydronium instead of pH so that the value was represented in a continuous measure of density instead of a value centered on 7.\n",
    "\n",
    "#### Bound Sulfur Dioxide\n",
    "Bound sulfur dioxide is calculated by subtracting the free sulfur dioxide from the total sulfur dioxide.  Free sulfur dioxide describes the amount of sulfur dioxide that is available for bonding, therefore the difference can be inferred as the amount of sulfur dioxide that is already bound and no longer available for bonding.\n",
    "\n",
    "Because total sulfur dioxide contains the value from free sulfur dioxide there is some multicolinearity introduced by the two variables.  To compensate for that multicolinearity this feature should be calculated and the total sulfur dioxide column should be dropped before modeling.\n",
    "\n",
    "#### Flavor Profiles\n",
    "During our research on the variables included in this dataset we found that some variables are considered to have more profound impacts on flavor than others.  By running a K-means clustering model on the most impactful variables, we found 4 disctinct \"flavor profiles\" that describe the flavor of a wine and highlight the prefences of the wine testers.\n",
    "\n",
    "\n",
    "### Engineered Feature Dictionary\n",
    "\n",
    "| **Variable Name** | **Explanation** | **Unit** | **Values** |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| Hydronium | A representation of pH in concentration | M/L | float |\n",
    "| Bound Sulfur Dioxide | Difference of free sulfur dioxide and total sulfur dioxide | mg/L | float |\n",
    "| Flavor Profile | K-means cluster using volatile acidity, chlorides, residual sugar, and alcohol | 0-3 | category |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into the notebook\n",
    "train, validate, test = wrangle.wrangle_data_and_split('both')\n",
    "\n",
    "train = model.drop_outliers(train, 'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# Exploration Summary\n",
    "<!-- I feel like something should be said here. -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "### Regardless of color, a wine with an ABV above 12% is much more likely to be of high quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:16: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Draw ABV boxen plot\n",
    "viz.abv_boxen_by_quality(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The the chart above we can see the distribution of Alcohol by Volume (ABV) for each quality.  For each quality score we can find wines as with a low ABV between 8% and 9% as well as a high ABV between 14.5% and 13%.  We can infer that ABV is a great predictor for good wines because the most dense regeions for each category show an upward trend.  \n",
    "\n",
    "However, the distributions for qualities 3 and 4 tell us a different story.  Because the distributions are quite similar, and in-fact have a higher mean than quality 5 wines, we can infer that there is something else going on that causes a wine to be considered a bad wine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red and white wines are different worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f26200; color: white; border-radius: 25px; padding: 15px; width: 55%\">\n",
    " <strong>Caution!</strong> <br>\n",
    "  A model only performs well for the world in which it was trained.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/1752025585.py:12: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Draw plots to show differences between red and white wines.\n",
    "fig, ax = plt.subplots(2,2,figsize=[10,7])\n",
    "fig.suptitle('Physicochemical differences between wines', fontsize=16)\n",
    "sns.histplot(data=train, x='chlorides', hue='type', ax=ax[0][0],alpha=.9)\n",
    "sns.histplot(data=train, x='residual_sugar', hue='type', ax=ax[0][1],alpha=.8)\n",
    "sns.histplot(data=train, x='volatile_acidity', hue='type', ax=ax[1][0],alpha=.9)\n",
    "sns.histplot(data=train, x='total_sulfur_dioxide', hue='type', ax=ax[1][1],alpha=.9)\n",
    "# Remove most of the legends to declutter the figure.\n",
    "ax[0][0].get_legend().remove()\n",
    "ax[1][0].get_legend().remove()\n",
    "ax[1][1].get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above demonstrates some of the noticeable differences between the types of wines.  It might come as no surprise to learn that red wines and white wines are different types of wines, but this distinction becomes very important when applying machine learning models.  A model is only good in the world it was trained in.  Because of this we have decided that exploring and modeling should be done on each wine type separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flavor Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/543709208.py:12: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate flavor profiles\n",
    "# Create the profiler instance\n",
    "profiler = model.FlavorProfile()\n",
    "# Fit it to the training data\n",
    "profiler.fit(train)\n",
    "# Assign clusters to the data\n",
    "train['flavor_profile'] = profiler.predict(train)\n",
    "# Draw the plot\n",
    "plt.figure(figsize=[10,5])\n",
    "sns.boxplot(data=train, x='flavor_profile', y='quality', hue='type')\n",
    "plt.title('Quality scores per flavor profile')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flavor_profile visualization](./img/plotly_flavor_profiles.png)\n",
    "\n",
    "\n",
    "By creating these clusters we discovered that the testers for this dataset hat a clear preference for strong, unsweetened wines.  In addition to being a strong predictor for quality, these clusters can help manufacturers market their wine to the appropriate customers.  For example, people who only drink socially might prefer sweeter wines with a low alcohol strength."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/224279765.py:7: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "train['eu_illegal'] = train.apply(viz.not_eu_legal, axis=1)\n",
    "plt.figure(\n",
    "    facecolor='white'\n",
    "    )\n",
    "plt.pie(train.eu_illegal.value_counts(), explode=(0,0.25), labels=['Legal', 'Not Legal'])\n",
    "plt.title('Only a small fraction of wines are not legal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, 15), (2755, 15))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.eu_illegal].shape, train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By testing if each observation's values fall within the limits defined by EU law we engineered the `eu_illegal` column.  We discovered only 26 wines out of the 2755 wines in our training dataset were not EU legal wines.  However we were surprised that the distribution of quality scores for the \"illegal\" wines looked very similar to the overal distribution of quality scores.  Due to this, we decided not to use this feature in any of our modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/226697335.py:4: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Display quality score distribution for not legal wiens\n",
    "sns.kdeplot(data=train[train.eu_illegal], x='quality', color=wine_colors[1])\n",
    "plt.title('Distribution of quality scores for Not Legal wines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydronium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Engineer the feature\n",
    "train['hydronium'] = 10**(-train['ph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Hydrogen (pH) is an arbitrary scale from 0 to 14 that describes how acidic or basic a solution is.  This is determined by its Hydronium concentration.  \n",
    "We exctacted the hydronium concentration knowing that the formula for pH is $-\\log{H_3O{+}}$, in turn the formula used to derive the hydronium concentration is $10^{-pH}$.  \n",
    "We chose to use hydronium instead of pH so that the value was represented in a continuous measure of density instead of a value centered on 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/1545469460.py:5: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Show the relationship between pH and Hydronium\n",
    "sns.set_palette(wine_palette_r)\n",
    "sns.lineplot(data=train, x='ph', y='hydronium')\n",
    "plt.title('Polynomial relationship between pH and Hydronium')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how the transformation changes the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/482441308.py:9: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Show comparison plot between pH and Hydronium\n",
    "sns.set_palette(wine_palette)\n",
    "fig, axes = plt.subplots(1,2, figsize=[10,4])\n",
    "sns.barplot(data=train, x='quality', y='hydronium', hue='type', ax=axes[0])\n",
    "sns.barplot(data=train, x='quality', y='ph', hue='type', ax=axes[1])\n",
    "fig.suptitle('Comparing pH to Hydronium against quality')\n",
    "for ax in axes:\n",
    "    ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above comparison demonstrates how transforming pH into Hydronium concentration can be more predictive of quality than pH alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most predictive qualities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout our exploration and testing, we found the following features to be the most predictive of a wine's quality for both red and white wines.\n",
    "- alcohol\n",
    "- volatile_acidity\n",
    "- citric_acid\n",
    "- residual_sugar\n",
    "- total_sulfur_dioxide\n",
    "- hydronium\n",
    "- density\n",
    "- ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the features list for later.\n",
    "feats = [\n",
    "    'alcohol',\n",
    "    'volatile_acidity',\n",
    "    'citric_acid',\n",
    "    'residual_sugar',\n",
    "    'total_sulfur_dioxide',\n",
    "    'hydronium',\n",
    "    'density',\n",
    "    'ions',\n",
    "    ]\n",
    "\n",
    "# Ensure features exist in dataset\n",
    "train = model.add_features(train)\n",
    "\n",
    "# A counter for iterating through feats\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the list of features is consistent across both wine colors, each one behaves differently for each color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare ABV\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Red and white wines behave similarly here, as the % Alcohol by Volume increases, so does the average quality score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Volatile acidity\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When comparing the effect of volatile acidity on a wine's quality, the need to model the wines seperately becomes even more clear.  Although both colors show a negative correllation to quality, there is a clear difference in the patterns.  A low quality white wine with a volatile acidity of 0.4 could be seen as similar to a high quality red wine with a volatile acidity of 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Citric Acid\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The concentration of citric acid tells a similar story and highlights the need to separate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Residual Sugar\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing residual sugar content also highlights the need for separate models.  We can see a much more dramatic variance in residual sugar content among the white wines that yeilds some predictive power while the residual sugar content of red wines seems to have no effect on quality \n",
    "- The non-linear pattern suggests that using polynomal features may be beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Total sulfur dioxide\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total sulfur dioxide content shows a similar story to the residual sugar content where the range differences in colors are important to keep separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Hydronium\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparing Hydronium concentrations highlights perhaps one of the most stark contrasts between red and white wines.  It appears that white wines become less acidic as they increase in quality whereas red wines become *more* acidic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Density\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Density seems to have a much more dramatic corellation with quality for white wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisarce/codeup-data-science/jtl_wine_quality/viz.py:62: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Compare Ions\n",
    "viz.regplot_compare(train, 'quality', feats[i])\n",
    "i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ions seem to be much more important for red wines than they are for white wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used for modeling\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be demonstrating the performance of our best models compared to a simple baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, declare the variables we will be feeding into the models.\n",
    "target = 'quality'\n",
    "feats = [\n",
    "    'alcohol',\n",
    "    'volatile_acidity',\n",
    "    'citric_acid',\n",
    "    'residual_sugar',\n",
    "    'total_sulfur_dioxide',\n",
    "    'hydronium',\n",
    "    'density',\n",
    "    'ions',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for modeling\n",
    "\n",
    "# Prepare the red wine samples\n",
    "red = wrangle.wrangle_data(\"red\")\n",
    "red = model.add_features(red)\n",
    "red_train, red_validate, red_test = wrangle.train_test_validate_split(red)\n",
    "red_train = model.drop_outliers(red_train, \"red\", method='manual')\n",
    "red_train, red_validate, red_test = [df[feats + [target]] for df in [red_train, red_validate, red_test]]\n",
    "\n",
    "# Prepare the white wine samples\n",
    "white = wrangle.wrangle_data(\"white\")\n",
    "white = model.add_features(white)\n",
    "white_train, white_validate, white_test = wrangle.train_test_validate_split(white)\n",
    "white_train = model.drop_outliers(white_train, \"white\", method='manual')\n",
    "white_train, white_validate, white_test = [df[feats + [target]] for df in [white_train, white_validate, white_test]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X and y sets used for red models\n",
    "r_xt = red_train[feats]\n",
    "r_xv = red_validate[feats]\n",
    "r_xs = red_test[feats]\n",
    "r_yt = red_train[target]\n",
    "r_yv = red_validate[target]\n",
    "r_ys = red_test[target]\n",
    "\n",
    "red_scaler = helpers.prep.train_scaler(r_xt)\n",
    "r_xt = red_scaler.transform(r_xt)\n",
    "r_xv = red_scaler.transform(r_xv)\n",
    "r_xs = red_scaler.transform(r_xs)\n",
    "\n",
    "red_poly = PolynomialFeatures(2)\n",
    "red_poly.fit(r_xt)\n",
    "r_xt_poly = red_poly.transform(r_xt)\n",
    "r_xv_poly = red_poly.transform(r_xv)\n",
    "r_xs_poly = red_poly.transform(r_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the X and y sets used for white models\n",
    "w_xt = white_train[feats]\n",
    "w_xv = white_validate[feats]\n",
    "w_xs = white_test[feats]\n",
    "w_yt = white_train[target]\n",
    "w_yv = white_validate[target]\n",
    "w_ys = white_test[target]\n",
    "\n",
    "white_scaler = helpers.prep.train_scaler(w_xt)\n",
    "w_xt = white_scaler.transform(w_xt)\n",
    "w_xv = white_scaler.transform(w_xv)\n",
    "w_xs = white_scaler.transform(w_xs)\n",
    "\n",
    "white_poly = PolynomialFeatures(3)\n",
    "white_poly.fit(w_xt)\n",
    "w_xt_poly = white_poly.transform(w_xt)\n",
    "w_xv_poly = white_poly.transform(w_xv)\n",
    "w_xs_poly = white_poly.transform(w_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and fit models\n",
    "red_models = {\n",
    "    'Mean Baseline': helpers.eval.BaselineModel(method='mean'),\n",
    "    'Linear Regression': LinearRegression(positive=True),\n",
    "    'Random Forest': RandomForestRegressor(max_depth=10),\n",
    "    'KNN Regression': KNeighborsRegressor(n_neighbors=5),\n",
    "}\n",
    "red_poly_models = {\n",
    "    'Linear Regression': LinearRegression(positive=True),\n",
    "    'Random Forest': RandomForestRegressor(max_depth=10),\n",
    "    'KNN Regression': KNeighborsRegressor(n_neighbors=5),\n",
    "}\n",
    "\n",
    "for name, model in red_models.items():\n",
    "    model.fit(r_xt, r_yt)\n",
    "for name, model in red_poly_models.items():\n",
    "    model.fit(r_xt_poly, r_yt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect scores for red models\n",
    "scores = {}\n",
    "for name, model in red_models.items():\n",
    "    tp = model.predict(r_xt)\n",
    "    vp = model.predict(r_xv)\n",
    "    scores[f'{name}'] = {\n",
    "        'type' : 'red',\n",
    "        'train_rmse' : mean_squared_error(r_yt, tp, squared=False),\n",
    "        'validate_rmse' : mean_squared_error(r_yv, vp, squared=False),\n",
    "        'tp': tp,\n",
    "        'vp': vp\n",
    "    }\n",
    "\n",
    "for name, model in red_poly_models.items():\n",
    "    tp = model.predict(r_xt_poly)\n",
    "    vp = model.predict(r_xv_poly)\n",
    "    scores[f'{name} (Polynomial)'] = {\n",
    "        'type' : 'red',\n",
    "        'train_rmse' : mean_squared_error(r_yt, tp, squared=False),\n",
    "        'validate_rmse' : mean_squared_error(r_yv, vp, squared=False),\n",
    "        'tp': tp,\n",
    "        'vp': vp\n",
    "    }\n",
    "\n",
    "# Store scores in a dataframe\n",
    "scores_df = pd.DataFrame.from_dict(scores, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>validate_rmse</th>\n",
       "      <th>tp</th>\n",
       "      <th>vp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Baseline</th>\n",
       "      <td>red</td>\n",
       "      <td>0.838951</td>\n",
       "      <td>0.803947</td>\n",
       "      <td>[5.641361256544503, 5.641361256544503, 5.64136...</td>\n",
       "      <td>[5.641361256544503, 5.641361256544503, 5.64136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>red</td>\n",
       "      <td>0.700431</td>\n",
       "      <td>0.701773</td>\n",
       "      <td>[5.181408708074526, 5.600099971704844, 5.12615...</td>\n",
       "      <td>[5.09168456875291, 5.4949158559919775, 5.29490...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>red</td>\n",
       "      <td>0.342062</td>\n",
       "      <td>0.617276</td>\n",
       "      <td>[4.252000015547554, 5.781321001617499, 5.15182...</td>\n",
       "      <td>[5.250529443020627, 5.659239868026149, 5.48402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regression</th>\n",
       "      <td>red</td>\n",
       "      <td>0.588769</td>\n",
       "      <td>0.682125</td>\n",
       "      <td>[4.6, 5.2, 5.0, 5.4, 5.6, 5.0, 5.8, 5.0, 6.2, ...</td>\n",
       "      <td>[5.2, 5.6, 5.2, 5.4, 5.2, 5.4, 4.8, 6.2, 5.2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression (Polynomial)</th>\n",
       "      <td>red</td>\n",
       "      <td>0.698293</td>\n",
       "      <td>0.683348</td>\n",
       "      <td>[5.203534593143311, 5.5924258553601, 5.1617620...</td>\n",
       "      <td>[5.121456620599672, 5.491387735632516, 5.30863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Polynomial)</th>\n",
       "      <td>red</td>\n",
       "      <td>0.341163</td>\n",
       "      <td>0.619635</td>\n",
       "      <td>[4.3185090933103645, 5.717676927545992, 5.1226...</td>\n",
       "      <td>[5.150091945902969, 5.622874233294231, 5.52090...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regression (Polynomial)</th>\n",
       "      <td>red</td>\n",
       "      <td>0.586810</td>\n",
       "      <td>0.684599</td>\n",
       "      <td>[4.6, 5.2, 5.0, 5.4, 5.6, 5.0, 5.8, 5.4, 6.2, ...</td>\n",
       "      <td>[5.0, 5.6, 5.4, 5.4, 5.2, 5.4, 4.8, 6.2, 5.4, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               type  train_rmse  validate_rmse  \\\n",
       "Mean Baseline                   red    0.838951       0.803947   \n",
       "Linear Regression               red    0.700431       0.701773   \n",
       "Random Forest                   red    0.342062       0.617276   \n",
       "KNN Regression                  red    0.588769       0.682125   \n",
       "Linear Regression (Polynomial)  red    0.698293       0.683348   \n",
       "Random Forest (Polynomial)      red    0.341163       0.619635   \n",
       "KNN Regression (Polynomial)     red    0.586810       0.684599   \n",
       "\n",
       "                                                                               tp  \\\n",
       "Mean Baseline                   [5.641361256544503, 5.641361256544503, 5.64136...   \n",
       "Linear Regression               [5.181408708074526, 5.600099971704844, 5.12615...   \n",
       "Random Forest                   [4.252000015547554, 5.781321001617499, 5.15182...   \n",
       "KNN Regression                  [4.6, 5.2, 5.0, 5.4, 5.6, 5.0, 5.8, 5.0, 6.2, ...   \n",
       "Linear Regression (Polynomial)  [5.203534593143311, 5.5924258553601, 5.1617620...   \n",
       "Random Forest (Polynomial)      [4.3185090933103645, 5.717676927545992, 5.1226...   \n",
       "KNN Regression (Polynomial)     [4.6, 5.2, 5.0, 5.4, 5.6, 5.0, 5.8, 5.4, 6.2, ...   \n",
       "\n",
       "                                                                               vp  \n",
       "Mean Baseline                   [5.641361256544503, 5.641361256544503, 5.64136...  \n",
       "Linear Regression               [5.09168456875291, 5.4949158559919775, 5.29490...  \n",
       "Random Forest                   [5.250529443020627, 5.659239868026149, 5.48402...  \n",
       "KNN Regression                  [5.2, 5.6, 5.2, 5.4, 5.2, 5.4, 4.8, 6.2, 5.2, ...  \n",
       "Linear Regression (Polynomial)  [5.121456620599672, 5.491387735632516, 5.30863...  \n",
       "Random Forest (Polynomial)      [5.150091945902969, 5.622874233294231, 5.52090...  \n",
       "KNN Regression (Polynomial)     [5.0, 5.6, 5.4, 5.4, 5.2, 5.4, 4.8, 6.2, 5.4, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## White Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and fit models\n",
    "white_models = {\n",
    "    'Mean Baseline': helpers.eval.BaselineModel(method='mean'),\n",
    "    'Linear Regression': LinearRegression(positive=True),\n",
    "    'Random Forest': RandomForestRegressor(max_depth=10),\n",
    "    'KNN Regression': KNeighborsRegressor(n_neighbors=5),\n",
    "}\n",
    "white_poly_models = {\n",
    "    'Linear Regression': LinearRegression(positive=True),\n",
    "    'Random Forest': RandomForestRegressor(max_depth=10),\n",
    "    'KNN Regression': KNeighborsRegressor(n_neighbors=5),\n",
    "}\n",
    "for name, model in white_models.items():\n",
    "    model.fit(w_xt, w_yt)\n",
    "for name, model in white_poly_models.items():\n",
    "    model.fit(w_xt_poly, w_yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect scores for white models\n",
    "scores = {}\n",
    "for name, model in white_models.items():\n",
    "    tp = model.predict(w_xt)\n",
    "    vp = model.predict(w_xv)\n",
    "    scores[f'{name}'] = {\n",
    "        'type' : 'white',\n",
    "        'train_rmse' : mean_squared_error(w_yt, tp, squared=False),\n",
    "        'validate_rmse' : mean_squared_error(w_yv, vp, squared=False),\n",
    "        'tp': tp,\n",
    "        'vp': vp\n",
    "    }\n",
    "\n",
    "for name, model in white_poly_models.items():\n",
    "    tp = model.predict(w_xt_poly)\n",
    "    vp = model.predict(w_xv_poly)\n",
    "    scores[f'{name} (Polynomial)'] = {\n",
    "        'type' : 'white',\n",
    "        'train_rmse' : mean_squared_error(w_yt, tp, squared=False),\n",
    "        'validate_rmse' : mean_squared_error(w_yv, vp, squared=False),\n",
    "        'tp': tp,\n",
    "        'vp': vp\n",
    "    }\n",
    "\n",
    "# Store them in a dataframe\n",
    "temp = pd.DataFrame.from_dict(scores, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>validate_rmse</th>\n",
       "      <th>tp</th>\n",
       "      <th>vp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Baseline</th>\n",
       "      <td>white</td>\n",
       "      <td>0.875574</td>\n",
       "      <td>0.926019</td>\n",
       "      <td>[5.912942271880819, 5.912942271880819, 5.91294...</td>\n",
       "      <td>[5.912942271880819, 5.912942271880819, 5.91294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>white</td>\n",
       "      <td>0.767971</td>\n",
       "      <td>0.819626</td>\n",
       "      <td>[5.760700277856108, 5.802331934610655, 6.42675...</td>\n",
       "      <td>[5.840623970700581, 5.492898184016904, 5.39559...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>white</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.753727</td>\n",
       "      <td>[5.80177584925685, 5.939411996741085, 6.888362...</td>\n",
       "      <td>[5.69224005600053, 5.009639240035029, 5.978087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regression</th>\n",
       "      <td>white</td>\n",
       "      <td>0.629194</td>\n",
       "      <td>0.805003</td>\n",
       "      <td>[5.8, 5.8, 6.6, 6.8, 6.0, 6.8, 5.2, 6.6, 5.6, ...</td>\n",
       "      <td>[6.0, 5.8, 5.4, 5.2, 5.0, 6.0, 5.2, 6.2, 6.6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression (Polynomial)</th>\n",
       "      <td>white</td>\n",
       "      <td>0.766012</td>\n",
       "      <td>0.819692</td>\n",
       "      <td>[5.769014193911812, 5.794248526453551, 6.48406...</td>\n",
       "      <td>[5.834425981644936, 5.4904627431583855, 5.4134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Polynomial)</th>\n",
       "      <td>white</td>\n",
       "      <td>0.419829</td>\n",
       "      <td>0.752931</td>\n",
       "      <td>[5.778505972898781, 5.922750245979631, 7.00845...</td>\n",
       "      <td>[5.825970721656278, 4.973231488052765, 5.85586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Regression (Polynomial)</th>\n",
       "      <td>white</td>\n",
       "      <td>0.633970</td>\n",
       "      <td>0.801577</td>\n",
       "      <td>[5.8, 5.8, 6.0, 6.8, 6.0, 6.8, 5.2, 6.6, 5.6, ...</td>\n",
       "      <td>[6.2, 5.6, 5.4, 5.4, 5.0, 6.4, 5.2, 6.0, 6.4, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 type  train_rmse  validate_rmse  \\\n",
       "Mean Baseline                   white    0.875574       0.926019   \n",
       "Linear Regression               white    0.767971       0.819626   \n",
       "Random Forest                   white    0.469100       0.753727   \n",
       "KNN Regression                  white    0.629194       0.805003   \n",
       "Linear Regression (Polynomial)  white    0.766012       0.819692   \n",
       "Random Forest (Polynomial)      white    0.419829       0.752931   \n",
       "KNN Regression (Polynomial)     white    0.633970       0.801577   \n",
       "\n",
       "                                                                               tp  \\\n",
       "Mean Baseline                   [5.912942271880819, 5.912942271880819, 5.91294...   \n",
       "Linear Regression               [5.760700277856108, 5.802331934610655, 6.42675...   \n",
       "Random Forest                   [5.80177584925685, 5.939411996741085, 6.888362...   \n",
       "KNN Regression                  [5.8, 5.8, 6.6, 6.8, 6.0, 6.8, 5.2, 6.6, 5.6, ...   \n",
       "Linear Regression (Polynomial)  [5.769014193911812, 5.794248526453551, 6.48406...   \n",
       "Random Forest (Polynomial)      [5.778505972898781, 5.922750245979631, 7.00845...   \n",
       "KNN Regression (Polynomial)     [5.8, 5.8, 6.0, 6.8, 6.0, 6.8, 5.2, 6.6, 5.6, ...   \n",
       "\n",
       "                                                                               vp  \n",
       "Mean Baseline                   [5.912942271880819, 5.912942271880819, 5.91294...  \n",
       "Linear Regression               [5.840623970700581, 5.492898184016904, 5.39559...  \n",
       "Random Forest                   [5.69224005600053, 5.009639240035029, 5.978087...  \n",
       "KNN Regression                  [6.0, 5.8, 5.4, 5.2, 5.0, 6.0, 5.2, 6.2, 6.6, ...  \n",
       "Linear Regression (Polynomial)  [5.834425981644936, 5.4904627431583855, 5.4134...  \n",
       "Random Forest (Polynomial)      [5.825970721656278, 4.973231488052765, 5.85586...  \n",
       "KNN Regression (Polynomial)     [6.2, 5.6, 5.4, 5.4, 5.0, 6.4, 5.2, 6.0, 6.4, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatonate scores into same dataframe\n",
    "scores_df = pd.concat([scores_df, temp])\n",
    "scores_df = scores_df.reset_index().rename(columns={'index': 'model'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/rf33rdr91vd7xt659vgf8qkm0000gn/T/ipykernel_41096/1477798376.py:6: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# And plot\n",
    "plt.figure(figsize=[7,5])\n",
    "ax = sns.barplot(data=scores_df, y='model', x='validate_rmse', hue='type', palette=wine_palette_r)\n",
    "ax.get_legend().remove()\n",
    "plt.title('Best models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "37b4e1d782780d9803a775659fc8b81e9cc61a0899d4564192c1f7cc3c556e45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
